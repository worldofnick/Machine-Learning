\documentclass[11pt]{article}
\usepackage{euscript}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{epsfig}
\usepackage{xspace}
\usepackage{color}
\usepackage{url}
\usepackage{subfig}
\usepackage{float}
\usepackage{array}
\graphicspath{ {images/} }
%%%%%%%  For drawing trees  %%%%%%%%%
\usepackage{tikz}
\usetikzlibrary{calc, shapes, backgrounds}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\textheight}{9in}
\setlength{\topmargin}{-0.600in}
\setlength{\headheight}{0.2in}
\setlength{\headsep}{0.250in}
\setlength{\footskip}{0.5in}
\flushbottom
\setlength{\textwidth}{6.5in}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\columnsep}{2pc}
\setlength{\parindent}{1em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newcommand{\eps}{\varepsilon}

\renewcommand{\c}[1]{\ensuremath{\EuScript{#1}}}
\renewcommand{\b}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\s}[1]{\textsf{#1}}
\newcommand{\tb}[1]{\textbf{#1}}

\newcommand{\E}{\textbf{\textsf{E}}}
\renewcommand{\Pr}{\textbf{\textsf{Pr}}}
\newcommand*{\escape}[1]{\texttt{\textbackslash#1}}


\title{\textbf{\underline{Adaptive Linear Neuron}}}


\author{Nick R. Porter}

\begin{document}
\maketitle

\section{Adaline Overview}

	\begin{itemize}
		\item Main difference to perceptron is the activation function.
		\item Activation function is define as $\phi(x,w) = x \cdot w$
		\item Activation function is used for learning the weights
		\item A new function called the quantizer is used to predict class labels
		\item Cost function SSE: $J(w) = \frac{1}{2} \Sigma_i ( (y^{(i)} - \phi(z^{(i)}))^2$
		\item Use gradient descent to minimize the cost function.
		\item Update of $w$ is same, $w := w + \Delta w$
		\item $\Delta w = -\alpha \Delta J(w)$
		\item $\Delta J(w) = - \Sigma_i (y^{(i)} - \phi(z^{i}))x^{(i)}_{j}$
		\item Also referred to as 'batch gradient descent'
	\end{itemize}
	
\end{document}
